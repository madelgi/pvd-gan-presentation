{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/madelgi/pvd-gan-presentation/blob/master/notebooks/gan_presentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugpZ-CISvCn1"
   },
   "source": [
    "# An Introduction to Generative Adversarial Networks\n",
    "\n",
    "A generative adversarial network (GAN) is a generative machine learning system developed in 2014, with numerous applications in both supervised and unsupervised contexts. Many of the impressive breakthroughs in generative modeling (e.g., [ThisPersonDoesNotExist.com](https://ThisPersonDoesNotExist.com)) use a GAN-based system behind the scenes. By the end of this talk, I hope to cover:\n",
    "\n",
    "1. What is a generative model?\n",
    "2. How do GANs work (in broad strokes)?\n",
    "3. How would you go about building a simple GAN?\n",
    "4. What are some examples of the current state-of-the-art in GANs?\n",
    "\n",
    "**Note**: Because we have a wide range of skill levels in this group, from hobbyists to Ph.D.'s in statistics, my goal isn't to get bogged down in theoretical or engineering details. I want to provide a birds-eye view of what GANs do and how they function. For folks interested in diving deeper, I've sprinkled some exercises throughout the write-up, and I've compiled links to papers and other resources at the end of the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eanV_NYE08NG"
   },
   "source": [
    "## Preliminaries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SDaLqoft0_OY"
   },
   "source": [
    "### Generative vs. Discriminative Models\n",
    "\n",
    "Broadly, statistical models can be grouped into two categories:\n",
    "\n",
    "1. **Discriminative**: A discriminative model learns the boundary between classes. Mathematically, we are learning the *conditional* probability distribution $P(Y|X)$.\n",
    "2. **Generative**: A generative model learns how the data is actually distributed, rather than just the boundaries between different classes. Mathematically, this is equivalent to learning the *joint* probability distribution $P(X, Y)$.\n",
    "  - A generative model can be transformed into a discriminative model (i.e., used for classification) via Bayes' rule. \n",
    "\n",
    "\n",
    "- **Example 1**: Consider a dataset of images of 0's and 1's, and you want to categorize each image as either a 0 or 1. A discriminative model can tell you whether something is a 0 or a 1, but it can't do anything else. A generative model actually understands what 0's and 1's look like, and it can generate new pictures that appear to be 0's or 1's (hence the \"generative\" in the name). A generative model goes through a slightly less direct process to categorize an image -- it asks, \"based on this data model I have, which class (0 or 1) is more likely to produce this image?\"  \n",
    "\n",
    "![generative_v_discriminative](static/generative_v_discriminative.png)\n",
    "\n",
    "\n",
    "- **Example 2** ([source](https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm)): Suppose you have the following data:\n",
    "  \n",
    "  `(1, 0), (1, 0), (2, 0), (2, 1)`\n",
    "  \n",
    "  Then a generative model would learn the following probability distribution `p(x, y)`:\n",
    "  \n",
    "  ```\n",
    "        y=0   y=1\n",
    "        ----------\n",
    "  x=1 | 1/2   0\n",
    "  x=2 | 1/4   1/4\n",
    "  ```\n",
    "  \n",
    "  A discriminative model would learn the following probability distribution `p(y|x)`\n",
    "  \n",
    "  ```\n",
    "        y=0   y=1\n",
    "        ----------\n",
    "  x=1 | 1     0\n",
    "  x=2 | 1/2   1/2\n",
    "  ```\n",
    "  \n",
    "    - **Exercise**: Consider what each distribution would look like if we added 16 more `(1, 0)` points to our dataset.\n",
    "    - **Exercise**: Think about how you can go from the model `p(x, y)` to `p(y|x)` (read about Bayes' rule). Can you go in the other direction, from `p(y|x)` to `p(x, y)`? Why or why not?\n",
    "    \n",
    "- **Which model should I use?**: If you need to generate new data, a generative model is likely the best choice! If you are classifying data, in most situations a discriminative model will produce better results than a generative model. At a high level, this is because the generative model is trying to solve a harder problem (what is the shape of the underlying data distribution) vs. the discriminative model, which is directly trying to solve the issue of classification.\n",
    "    - **Note**: Reality is slightly more nuanced: [Ng and Jordan](http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf) found that, while discriminative models usually outperform generative models for the purposes of classification, in a scenario with limited training data, a generative model may outperform a discriminative model. In their words, \"While discriminative learning has lower [...] error, a generative classifier may also approach its (higher) [...] error much faster\" (i.e., the learning algorithm will converge faster).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2DvZ80UR054j"
   },
   "source": [
    "### Neural networks \n",
    "\n",
    "TODO this section can be as long or as short as needed. Ideally it would be short, so we can focus more on GANs themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mqr0v0CJ1XYE"
   },
   "source": [
    "## How Do GANs Work?\n",
    "\n",
    "After all of those preliminaries, we are ready to talk about GANs. Here is a cartoon of a GAN:\n",
    "\n",
    "![simple_gan](static/simple_gan_diagram.png)\n",
    "\n",
    "- A GAN is a _system_ of two neural networks, a _Generator_ and _Discriminator_.\n",
    "- The generator takes as input some sort of random noise (you can just think of this as a seed value, i.e., don't worry about it too much) and outputs some generated data. This generated data is supposed to \"spoof\" some real data distribution. In the diagram above, our underlying data distribution is pictures of cats. \n",
    "- The discriminator takes in images from our real data distribution along with our \"spoofed\" data, and tries to distinguish between the two. In other words, the discriminator solves a binary classification problem where the two possible classes are \"real cat\" and \"fake cat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process\n",
    "\n",
    "GANs play a game with one another. The generator is responsible for creating data that is supposed to look like data from some other distribution (e.g., images of cats). The discriminator is responsible for distinguishing between real and generated images.\n",
    "\n",
    "The diagram below is a more detailed version of the diagram earlier in this section, with some expository detail surrounding the training process:\n",
    "\n",
    "![gan_training](static/gan_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick notes:**\n",
    "\n",
    "- Again, the generator and discriminator are both neural networks. They can be incredibly complex, but the above image abstracts that complexity away to focus on the overall training scheme.\n",
    "- The generator takes as inputs random values pulled from a normal distribution centered at 0, $z\\sim N(0,1)$. You can think of this as a seed value. Depending on the problem-type, the input may be more meaningful. E.g., if we were building a GAN to do super-resolution, the input would be a low-resolution image. \n",
    "- We represent the neural networks in functional notation, $G$ and $D$:\n",
    "\\begin{align}\n",
    "G: X\\mapsto Y, \\quad\\quad D: Y\\mapsto \\{0, 1\\}\n",
    "\\end{align}\n",
    "  $G$ maps values from some input distribution (in this case, $X=N(0,1)$) to some output distribution $Y$ -- in our cat example above, $Y$ might be the space of $32\\times 32$ images. The discriminator takes values from $Y$, and tries to determine whether the value comes from our real dataset, or if it has been created by the generator. In the cat image example, if our generator solely produces images of all black pixels, then our discriminator will have a pretty easy time distinguishing those from real cat pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUzAF45w1aGi"
   },
   "source": [
    "## Building a Simple GAN (and Training Pitfalls)\n",
    "\n",
    "In this section, we lay out the architecture of a very simple GAN, and explore some of the training difficulties that arise with GANs. We are going to be following [this](https://blog.paperspace.com/implementing-gans-in-tensorflow/) tutorial, but our implementation will be in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/max/.local/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (train.py, line 23)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/max/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-2-d85e742cad76>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import pvd_gan_presentation as pvd\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/max/projects/pvd-gan-presentation/src/pvd_gan_presentation/__init__.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from .train import (\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/max/projects/pvd-gan-presentation/src/pvd_gan_presentation/train.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    'kstep': 5,\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import pvd_gan_presentation as pvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement and Data Set\n",
    "\n",
    "We are going to use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiSCw2UG3Ecx"
   },
   "source": [
    "### Architecture\n",
    "\n",
    "As discussed previously, our GAN consists of two components: the generator and discriminator. The generator is responsible for generating data, and the discriminator is responsible for differentiating between generated and \"real\" data. Execute the two cells below to view the source code and architecture of each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvd.PVDDiscriminator??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvd.PVDGenerator??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNL_jTHu3YPB"
   },
   "source": [
    "### Training: Initial Attempt and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "Iteration 0 [D loss: 0.39345186948776245, acc.: 51.953125] [G loss: None]\n",
      "Iteration 100 [D loss: 0.07355420291423798, acc.: 0.0] [G loss: 2.042599678039551]\n",
      "Iteration 200 [D loss: 0.0005733341677114367, acc.: 0.0] [G loss: 6.852892875671387]\n",
      "Iteration 300 [D loss: 3.547575033735484e-07, acc.: 0.0] [G loss: 14.302242279052734]\n",
      "Iteration 400 [D loss: 4.1566825537131535e-09, acc.: 0.0] [G loss: 18.793655395507812]\n",
      "Iteration 500 [D loss: 2.1099559877058027e-09, acc.: 0.0] [G loss: 20.126449584960938]\n",
      "Iteration 600 [D loss: 8.541060636524378e-10, acc.: 0.0] [G loss: 21.07253646850586]\n",
      "Iteration 700 [D loss: 5.404268144104662e-10, acc.: 0.0] [G loss: 21.44860076904297]\n",
      "Iteration 800 [D loss: 2.872685145316467e-10, acc.: 0.0] [G loss: 21.868009567260742]\n",
      "Iteration 900 [D loss: 1.6782746026233752e-10, acc.: 0.0] [G loss: 22.19478988647461]\n",
      "Iteration 1000 [D loss: 1.1075490524703469e-10, acc.: 0.0] [G loss: 22.453006744384766]\n",
      "Iteration 1100 [D loss: 7.121529060905019e-11, acc.: 0.0] [G loss: 22.80759048461914]\n",
      "Iteration 1200 [D loss: 7.945741981041365e-11, acc.: 0.0] [G loss: 22.867782592773438]\n",
      "Iteration 1300 [D loss: 2.005124510873202e-09, acc.: 0.0] [G loss: 22.028583526611328]\n",
      "Iteration 1400 [D loss: 1.6344132713896897e-09, acc.: 0.0] [G loss: 21.84279441833496]\n",
      "Iteration 1500 [D loss: 1.5529662000801636e-09, acc.: 0.0] [G loss: 22.334842681884766]\n",
      "Iteration 1600 [D loss: 1.3503744789034045e-09, acc.: 0.0] [G loss: 22.36004066467285]\n",
      "Iteration 1700 [D loss: 1.1232679231198972e-09, acc.: 0.0] [G loss: 22.848285675048828]\n",
      "Iteration 1800 [D loss: 2.4925963515443073e-09, acc.: 0.0] [G loss: 22.349903106689453]\n",
      "Iteration 1900 [D loss: 3.3975293689536556e-09, acc.: 0.0] [G loss: 22.3957462310791]\n",
      "Iteration 2000 [D loss: 5.047777307254364e-09, acc.: 0.0] [G loss: 21.808422088623047]\n",
      "Iteration 2100 [D loss: 3.223988187528448e-08, acc.: 0.0] [G loss: 21.08048439025879]\n",
      "Iteration 2200 [D loss: 3.2289321097778156e-05, acc.: 0.0] [G loss: 26.692184448242188]\n",
      "Iteration 2300 [D loss: 0.007209364324808121, acc.: 0.5859375] [G loss: 39.40803527832031]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-199c99e8c5af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPVDDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPVDGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/pvd-gan-presentation/src/pvd_gan_presentation/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_iters, batch_size, visualize)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_pts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mZ_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mX_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/pvd-gan/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen = pvd.PVDGenerator()\n",
    "disc = pvd.PVDDiscriminator()\n",
    "trainer = pvd.PVDGAN(generator=gen, discriminator=disc)\n",
    "trainer.train(visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m727oDkm3bxC"
   },
   "source": [
    "\n",
    "\n",
    "### Optimization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X61nL6zU4f5U"
   },
   "source": [
    "## Current State of the Art\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StyleGAN 2\n",
    "\n",
    "- Example usage: ![ThisPersonDoesNotExist](https://thispersondoesnotexist.com/)\n",
    "- Architecture overview\n",
    "- Training routine"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPc/6HzNb43+YHbYB7Zzx0X",
   "include_colab_link": true,
   "name": "gan-presentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
